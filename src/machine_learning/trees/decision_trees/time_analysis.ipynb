{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "sys.path.append('../../utils')\n",
    "from utils import time_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time fiability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the classifier performs over time when learning for a few days and then testing on completely new values. Let's first try by learning on 6000 malwares starting on the 15th of June. This should cover approximatively a week of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['snapshots/tree_3_20190615_6000.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = pd.read_csv(\"../../../dumps/time_analysis/threshold_3/3_20190615_6000.csv\")\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data_train = gt[cols]\n",
    "target_train = gt['label']\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=7,min_samples_split=10,min_samples_leaf=7,random_state=0)\n",
    "tree.fit(data_train, target_train)\n",
    "dump(tree,\"snapshots/tree_3_20190615_6000.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to provide a relevant analysis, it makes sense not to compare performances on malwares that were checked in a period close to the ones used to build the training set. Therefore, we'll make the comparison on a dataset that has been generated at least two or three months after the older result from our reference set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.993\n",
      "Accuracy on test set: 0.919\n"
     ]
    }
   ],
   "source": [
    "tree = load(\"snapshots/tree_3_20190615_6000.joblib\")\n",
    "\n",
    "gt = pd.read_csv(\"../../../dumps/time_analysis/threshold_3/3_20190808_1000.csv\")\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data_test = gt[cols]\n",
    "target_test = gt['label']\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : really good performances of decision trees when learning and testing period are close but seems to overfit over time because bad performances on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we decide to normalize too ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['snapshots/tree_3_20190615_6000n.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = pd.read_csv(\"../../../dumps/time_analysis/threshold_3/3_20190615_6000.csv\")\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data_train = gt[cols]\n",
    "target_train = gt['label']\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaler.fit(data_train)\n",
    "data_train = scaler.transform(data_train)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=7,min_samples_split=10,min_samples_leaf=7,random_state=0)\n",
    "tree.fit(data_train, target_train)\n",
    "dump(tree,\"snapshots/tree_3_20190615_6000n.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.992\n",
      "Accuracy on test set: 0.971\n"
     ]
    }
   ],
   "source": [
    "tree = load(\"snapshots/tree_3_20190615_6000n.joblib\")\n",
    "\n",
    "gt = pd.read_csv(\"../../../dumps/time_analysis/threshold_3/3_20190808_1000.csv\")\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data_test = gt[cols]\n",
    "target_test = gt['label']\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaler.fit(data_test)\n",
    "data_test = scaler.transform(data_test)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting to see that in this case, normalization offers such a great improvement !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's iterate the process and see how performances are impacted when increasing the size of the training set (the test set used in the same as in the previous experience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptation threshold : 1/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.980333       0.954\n",
      "                       14000                   2               0.981786       0.752\n",
      "                       21000                   3               0.970238       0.77\n",
      "                       31000                   4.42857         0.926548       0.697\n",
      "Acceptation threshold : 2/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.9905         0.98\n",
      "                       14000                   2               0.989429       0.991\n",
      "                       21000                   3               0.981          0.984\n",
      "                       31000                   4.42857         0.929935       0.968\n",
      "Acceptation threshold : 3/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.993167       0.919\n",
      "                       14000                   2               0.993214       0.92\n",
      "                       21000                   3               0.993524       0.987\n",
      "                       31000                   4.42857         0.98671        0.989\n",
      "Acceptation threshold : 4/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.991333       0.923\n",
      "                       14000                   2               0.991429       0.969\n",
      "                       21000                   3               0.990095       0.966\n",
      "                       31000                   4.42857         0.986065       0.97\n",
      "Acceptation threshold : 5/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.991333       0.923\n",
      "                       14000                   2               0.991429       0.969\n",
      "                       21000                   3               0.990095       0.966\n",
      "                       31000                   4.42857         0.986065       0.97\n"
     ]
    }
   ],
   "source": [
    "time_comparison('tree','../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sense, the more we increase the size of the training test the more the test precision increases for the 3 latter cases. I guess this is also due to the fact that the last malwares are \"closer\" to the ones in the test set.\n",
    "Also intersting to notice that the 2 latter cases have the exact same accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
