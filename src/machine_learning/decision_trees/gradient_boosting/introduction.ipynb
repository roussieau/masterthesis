{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosted regression trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principle : In contrast to the random forest approach, gradient boosting works by building trees in a serial man‚Äê ner, where each tree tries to correct the mistakes of the previous one. By default, there is no randomization in gradient boosted regression trees; instead, strong pre-pruning is used. Gradient boosted trees often use very shallow trees, of depth one to five, which makes the model smaller in terms of memory and makes predictions faster. Each tree can only provide good predictions on part of the data, and so more and more trees are added to iteratively improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.981\n",
      "Accuracy on test set: 0.819\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../../../dumps/2020.01.13-14.25.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = 0.20, random_state = 0)\n",
    "\n",
    "tree = GradientBoostingClassifier(random_state=0)\n",
    "tree.fit(data_train, target_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the training set accuracy is quite close to 100% and the test set accuracy is pretty low, we are likely to be overfitting. To reduce this overfitting, we mght try to apply pre-pruning by limiting the maximum depth or lower the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
