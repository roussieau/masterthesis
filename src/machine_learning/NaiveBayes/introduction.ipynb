{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principle : Naive Bayes classifiers are a family of classifiers that are quite similar to the linear models discussed in the previous section. However, they tend to be even faster in training. The price paid for this efficiency is that naive Bayes models often provide generalization performance that is slightly worse than that of linear classifiers like LogisticRegression and LinearSVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.34\n",
      "Test set accuracy: 0.35\n",
      "Test set accuracy: 0.34\n",
      "Test set accuracy: 0.43\n",
      "Test set accuracy: 0.48\n",
      "Test set accuracy: 0.53\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../../dumps/references/2020.01.13-14.25.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "values = [0.1,0.2,0.4,0.6,0.8,0.9]\n",
    "\n",
    "for i in values:\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = i, random_state = 0)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data_train)\n",
    "    data_train = scaler.transform(data_train)\n",
    "    data_test = scaler.transform(data_test)\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    gnb.fit(data_train, target_train)\n",
    "    print(\"Test set accuracy: {:.2f}\".format(gnb.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, no matter of big the test size is, the performances with the Gaussian classifier are really bad for this dataset. Let's try with more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.13\n",
      "Test set accuracy: 0.17\n",
      "Test set accuracy: 0.21\n",
      "Test set accuracy: 0.24\n",
      "Test set accuracy: 0.33\n",
      "Test set accuracy: 0.46\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../../dumps/references/2020.02.10-12.14.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "values = [0.1,0.2,0.4,0.6,0.8,0.9]\n",
    "\n",
    "for i in values:\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = i, random_state = 0)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data_train)\n",
    "    data_train = scaler.transform(data_train)\n",
    "    data_test = scaler.transform(data_test)\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    gnb.fit(data_train, target_train)\n",
    "    print(\"Test set accuracy: {:.2f}\".format(gnb.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is even worse ! The reaseon why this algorithm is so fast but also so bad at generalization is because it learns parameters by looking at each feature individually and collect simple per-class statistics from each feature. Since we have a huge diversity in our dataset, the GaussianNB gives quite bad results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the Bernouilli distribution for different test sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.72\n",
      "Test set accuracy: 0.70\n",
      "Test set accuracy: 0.71\n",
      "Test set accuracy: 0.70\n",
      "Test set accuracy: 0.73\n",
      "Test set accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../../dumps/references/2020.02.10-12.14.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "values = [0.1,0.2,0.4,0.6,0.8,0.9]\n",
    "\n",
    "for i in values:\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = i, random_state = 0)\n",
    "    \n",
    "    gnb = BernoulliNB()\n",
    "\n",
    "    gnb.fit(data_train, target_train)\n",
    "    print(\"Test set accuracy: {:.2f}\".format(gnb.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performances are not that bad but one has to know that BernouilliNB is assumes binary data (opposite to the GaussianNB which works for any kind of continuous data). We should therefore perform some tuning and only keep boolean values in our dataset. Let's scale the data to see if it improves the accuray :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.91\n",
      "Test set accuracy: 0.90\n",
      "Test set accuracy: 0.89\n",
      "Test set accuracy: 0.88\n",
      "Test set accuracy: 0.88\n",
      "Test set accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../../dumps/references/2020.02.10-12.14.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "values = [0.1,0.2,0.4,0.6,0.8,0.9]\n",
    "\n",
    "for i in values:\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = i, random_state = 0)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data_train)\n",
    "    data_train = scaler.transform(data_train)\n",
    "    data_test = scaler.transform(data_test)\n",
    "    gnb = BernoulliNB()\n",
    "\n",
    "    gnb.fit(data_train, target_train)\n",
    "    print(\"Test set accuracy: {:.2f}\".format(gnb.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impressive to see how great our results are now ! We can conclude that scaling is therefore quite game-changing in the case of this distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the Multinomial distribution. Note that this distribution only accepts non-negative values, therefore we have either to parse our dataset and remove all rows where feature values are below 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3771, 119)\n",
      "Test set accuracy: 0.77\n",
      "Test set accuracy: 0.80\n",
      "Test set accuracy: 0.83\n",
      "Test set accuracy: 0.87\n",
      "Test set accuracy: 0.92\n",
      "Test set accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../../dumps/references/2020.02.10-12.14.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "for col in cols:\n",
    "    gt = gt.drop(gt[gt[col] < 0 ].index)\n",
    "data = gt[cols]\n",
    "print(data.shape)\n",
    "target = gt['label']\n",
    "\n",
    "values = [0.1,0.2,0.4,0.6,0.8,0.9]\n",
    "\n",
    "for i in values:\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = i, random_state = 0)\n",
    "    \n",
    "    gnb = MultinomialNB()\n",
    "\n",
    "    gnb.fit(data_train, target_train)\n",
    "    print(\"Test set accuracy: {:.2f}\".format(gnb.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or use some preprocessing to scale all values between 0 and 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7977, 119)\n",
      "Test set accuracy: 0.92\n",
      "Test set accuracy: 0.90\n",
      "Test set accuracy: 0.89\n",
      "Test set accuracy: 0.89\n",
      "Test set accuracy: 0.88\n",
      "Test set accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../../dumps/references/2020.02.10-12.14.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "print(data.shape)\n",
    "target = gt['label']\n",
    "\n",
    "values = [0.1,0.2,0.4,0.6,0.8,0.9]\n",
    "\n",
    "for i in values:\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = i, random_state = 0)\n",
    "\n",
    "    gnb = MultinomialNB()\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(data_train)\n",
    "    data_train = scaler.transform(data_train)\n",
    "    data_test = scaler.transform(data_test)\n",
    "\n",
    "    gnb.fit(data_train, target_train)\n",
    "    print(\"Test set accuracy: {:.2f}\".format(gnb.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : all the distributions we tested definitely need some scaling preprocessing. The Gaussian distribution didn't perform that well while Bernouilli's distribution provided the best results after normalization. The multinomial distribution quite good performances too but required removing some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
