{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "sys.path.append('../utils')\n",
    "from utils import time_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time fiability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the classifier performs over time when learning for a few days and then testing on completely new values. Let's first try by learning on 6000 malwares starting on the 15th of June. This should cover approximatively a week of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['snapshots/tree_default_20190615_6000.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = pd.read_csv(\"../../dumps/default_20190615_6000.csv\")\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data_train = gt[cols]\n",
    "target_train = gt['label']\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4,min_samples_split=0.1,min_samples_leaf=10,random_state=0)\n",
    "tree.fit(data_train, target_train)\n",
    "dump(tree,\"snapshots/tree_default_20190615_6000.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to provide a relevant analysis, it makes sense not to compare performances on malwares that were checked in a period close to the ones used to build the training set. Therefore, we'll make the comparison on a dataset that has been generated at least two or three months after the older result from our reference set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.946\n",
      "Accuracy on test set: 0.640\n"
     ]
    }
   ],
   "source": [
    "tree = load(\"snapshots/tree_default_20190615_6000.joblib\")\n",
    "\n",
    "gt = pd.read_csv(\"../../dumps/default_20190808_1000.csv\")\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data_test = gt[cols]\n",
    "target_test = gt['label']\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : really good performances of decision trees when learning and testing period are close but seems to overfit over time because bad performances on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we decide to normalize too ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['snapshots/tree_default_20190615_6000n.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = pd.read_csv(\"../../dumps/default_20190615_6000.csv\")\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data_train = gt[cols]\n",
    "target_train = gt['label']\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaler.fit(data_train)\n",
    "data_train = scaler.transform(data_train)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4,min_samples_split=0.1,min_samples_leaf=10,random_state=0)\n",
    "tree.fit(data_train, target_train)\n",
    "dump(tree,\"snapshots/tree_default_20190615_6000n.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.926\n",
      "Accuracy on test set: 0.923\n"
     ]
    }
   ],
   "source": [
    "tree = load(\"snapshots/tree_default_20190615_6000n.joblib\")\n",
    "\n",
    "gt = pd.read_csv(\"../../dumps/default_20190808_1000.csv\")\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data_test = gt[cols]\n",
    "target_test = gt['label']\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaler.fit(data_test)\n",
    "data_test = scaler.transform(data_test)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting to see that in this case, normalization offers such a great improvement !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's iterate the process and see how performances are impacted when increasing the size of the training set (the test set used in the same as in the previous experience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptation threshold : 1/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.9405         0.868\n",
      "                       14000                   2               0.936857       0.803\n",
      "                       21000                   3               0.923333       0.669\n",
      "                       31000                   4.42857         0.868774       0.609\n",
      "Acceptation threshold : 2/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.924          0.716\n",
      "                       14000                   2               0.954714       0.716\n",
      "                       21000                   3               0.96619        0.776\n",
      "                       31000                   4.42857         0.897452       0.635\n",
      "Acceptation threshold : default/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.946          0.64\n",
      "                       14000                   2               0.943429       0.64\n",
      "                       21000                   3               0.931286       0.658\n",
      "                       31000                   4.42857         0.955645       0.762\n",
      "Acceptation threshold : 4/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.9705         0.941\n",
      "                       14000                   2               0.972429       0.938\n",
      "                       21000                   3               0.95881        0.941\n",
      "                       31000                   4.42857         0.966387       0.966\n",
      "Acceptation threshold : 5/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.9705         0.941\n",
      "                       14000                   2               0.972429       0.938\n",
      "                       21000                   3               0.95881        0.941\n",
      "                       31000                   4.42857         0.966387       0.966\n"
     ]
    }
   ],
   "source": [
    "time_comparison('tree','../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sense, the more we increase the size of the training test the more the test precision increases. I guess this is also due to the fact that the last malwares are \"closer\" to the ones in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
