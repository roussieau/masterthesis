{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tabulate import tabulate\n",
    "from joblib import dump, load\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "sys.path.append('../')\n",
    "from LinearModels import display_plot_logreg, display_plot_svc\n",
    "sys.path.append('../../utils')\n",
    "from utils import feature_selection, thomas_parser, PCA_reduction, perf, time_comparison\n",
    "from toBoolean import convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time fiability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['snapshots/logreg_default_20190615_6000.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = pd.read_csv(\"../../../dumps/default_20190615_6000.csv\")\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data_train = gt[cols]\n",
    "target_train = gt['label']\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaler.fit(data_train)\n",
    "data_train = scaler.transform(data_train)\n",
    "\n",
    "tree = LogisticRegression(C=0.01, max_iter=100,random_state=0)\n",
    "tree.fit(data_train, target_train)\n",
    "dump(tree,\"snapshots/logreg_default_20190615_6000.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.905\n",
      "Accuracy on test set: 0.896\n"
     ]
    }
   ],
   "source": [
    "tree = load(\"snapshots/logreg_default_20190615_6000.joblib\")\n",
    "\n",
    "gt = pd.read_csv(\"../../../dumps/default_20190808_1000.csv\")\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data_test = gt[cols]\n",
    "target_test = gt['label']\n",
    "\n",
    "data_test = scaler.transform(data_test)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion (for both classifiers) : time does clearly impact on the learning of these two classifiers. We observe a drop of performance of around 10% which is quite significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptation threshold : 1/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.7965         0.691\n",
      "                       14000                   2               0.782857       0.691\n",
      "                       21000                   3               0.754286       0.691\n",
      "                       31000                   4.42857         0.690194       0.695\n",
      "Acceptation threshold : 2/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.868833       0.855\n",
      "                       14000                   2               0.856286       0.855\n",
      "                       21000                   3               0.827905       0.855\n",
      "                       31000                   4.42857         0.760935       0.855\n",
      "Acceptation threshold : default/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.905333       0.896\n",
      "                       14000                   2               0.902714       0.896\n",
      "                       21000                   3               0.889619       0.896\n",
      "                       31000                   4.42857         0.882935       0.896\n",
      "Acceptation threshold : 4/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.953167        0.94\n",
      "                       14000                   2               0.947786        0.94\n",
      "                       21000                   3               0.938952        0.94\n",
      "                       31000                   4.42857         0.938935        0.94\n",
      "Acceptation threshold : 5/5 \n",
      "\n",
      "  # malwares in training set    Approx. period in weeks    Training acc    Test acc\n",
      "----------------------------  -------------------------  --------------  ----------\n",
      "                        6000                   0.857143        0.953167        0.94\n",
      "                       14000                   2               0.947786        0.94\n",
      "                       21000                   3               0.938952        0.94\n",
      "                       31000                   4.42857         0.938935        0.94\n"
     ]
    }
   ],
   "source": [
    "time_comparison('log','../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase the size of the training set doesn't improve the accuracies, it either stagnates or even decreases a bit. It's probably because the classifiers learn more informations that are spread around a lot of different values and therefore have more trouble to come out with good weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
