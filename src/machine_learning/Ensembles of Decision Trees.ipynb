{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principle : a random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.844\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../dumps/2020.01.13-14.25.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = 0.20, random_state = 0)\n",
    "\n",
    "tree = RandomForestClassifier(random_state=0)\n",
    "tree.fit(data_train, target_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that compared to the single decision tree, we get better results, without tuning any parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now carry on with a bigger dataset and try with different values of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_csv('../dumps/2020.02.10-12.14.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*n_estimators* represents the number of trees in the forest. Usually the higher the number of trees the better to learn the data. However, adding a lot of trees can slow down the training process considerably, therefore we do a parameter search to find the sweet spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x120202490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxV9Z3/8dcnCSEEwpqgYGRRUfY14EItKCJoFRWtda9OFbWj004Hp1j9ubVOa6XO1I62g60btSpirbZiRQWq1o2wyr4oyiaEPSEkJLmf3x/n3HATbiBgbm4g7+fjcR8593u2zz03OZ98v99zvsfcHRERkepSkh2AiIg0TEoQIiISlxKEiIjEpQQhIiJxKUGIiEhcShAiIhJXWrIDqCvZ2dnepUuXZIchInJEmTNnzhZ3z4k376hJEF26dCE/Pz/ZYYiIHFHM7Iua5qmJSURE4lKCEBGRuJQgREQkLiUIERGJK2EJwsyeNLPNZraohvlmZo+a2SozW2hmA2PmfdfMVoav7yYqRhERqVkiaxBPA6MPMP88oFv4Ggf8FsDM2gL3AqcCQ4B7zaxNAuMUEZE4EpYg3P1dYNsBFrkIeNYDHwGtzawDMAp4y923uft24C0OnGhERCQBknkfxHHA2pj368KymsrlANwdM6Mi4iz/qpDcts1okZ7G8k2FdGiVQXpaCn9f9BWtM5twQnYLPv58KwCZ6Wl8sHor5RURjm+bSVqqAVBW7ny5rZide8ri7i8zPZUOrTNYuHYna7cXk9umGTuKyygoLK23zywigd7HteKZfxlS59s9om+UM7NxBM1TdOrUKcnRJN7qgiLu/+sSzjolh82FpTz/yZec2rUtrZul8+qC9bRo2oSyigg795SRlmK0yEhjR3EZKQbNmqSye29F3O1mNU0jIz11v5P7sS0zaNM8HYuzzq6SMjYs3MPJx2QxoFMb1m8vpmPrZgzs3IaUeCuISMLktslMyHaTmSDWA8fHvM8Ny9YDw6uVz4q3AXefBEwCyMvLO2oejbd9915mLNvMBf06UFxawawVmxnYqQ23TJ7Dmq27eXdFAQBnnZLDx59vo6Ssggv7dsQM3OG0E9qxqqCIgsJSTu3ali+3FVNQWMqlg3IpKatgzZbdnHpCOzLSUtlevJeeHVvSJDWFveURIuETBlPMSE87cAtkJOKkKBuIHLWSmSBeA24zsxcIOqR3uvtGM3sT+K+YjulzgTuTFWR9WbutmFfmrWf4KTn859SFLPuqkD+8/znbdu/lq10lAJjB5H85ldaZTWiSmsIpx2ZRWl5BRcTJTK/9V3lmt33DrnRqt+8/j4MlhOqUHESObglLEGb2PEFNINvM1hFcmdQEwN1/B0wDzgdWAcXADeG8bWb2U2B2uKkH3P1And1HnGh/weZdJXyyZhsjex7Drc/NYdH6XTzy1grS01L40ciTefKfn9MmM53fX5fHh59tpVv7FnyjW3aVbTVNS03SpxCRo525Hx0tM3l5ed5QB+v764INzP1yO/dc0JMn3vuMqXPW8fQNQ7j1ubksWLuD41o3Y/2OPfzXJX3YtruUQZ3bcvqJ7SgqLSc9NeWQ/7MXEaktM5vj7nnx5h3RndRHit/MWMmKTUUM6NSGX7+9kt17Kxj1P+9SWFLOd/KO5y/z13PZoFyuOrVqR3uLpvp6RCR5dAZKkE27SigqLcfdWbGpCIAfvTif8ogz4bzu/PLvyxjTryMPXdaXuy/oQfND6EMQEakPOislyH9MWcCCtTu4oF9HAO4YdQoPv7mcUb2O4ZZhJ3J+7w50aJ0BQFZGk2SGKiISlxJEAuwo3suHn22lIuI8/8mXDOrchluGnUgk4lw8ILjnL/bqIRGRhkgJog6t2lxEWUWEpRt3URFxrhxyPM9/spbzeh9Laopx+4huyQ5RRKTWlCC+pndXFJCelsKpXdty8+R8Nu4soVv7FhzTsikPXtyHUb2O5bQT2iU7TBGRQ6YEcRjue20xXdplcv3Qrtz5508pj0R44ro8VhfsxgwWrNvJNad1IiXFGH5K+2SHKyJyWHSB/SFyd6bOWcdzH3/J5l0lrN+xh027SrnjpYWkphiPXjGAZk1Subi/xhcUkSObahCHaNvuvRSVlrNycxFvL90MBAPhLd9UyDdPzuHCfh05v08HUjUMhYgc4VSDqKVIxIlEnC+2FVeWPfHeZ6SnpvBvYefzhX07ACg5iMhRQTWIWrrwf99nRPf2nJDTorLs8y27GdCpNTcM7UJWRhoXqVlJRI4iShC1EIk4y74qJC01hdSUFMxgUKc25H+xnYGd2pDRJJVrTuuc7DBFROqUmphqYceeMioiztINu1i5uZBjW2bwzZODIbMHdtLjskXk6KQEUQtbioInre2tiPCP5QV0apvJBX07MPSkdgw9Sfc4iMjRSU1MB5C/ZhtdsptXeRRnYWk5ndtlckJOC5678bQkRicikliqQdQgEnGu+cPH/G7W6soahIUXJ3Vu1zyJkYmI1A8liBrs2FNGSVmEL8LnOQMMOL41AJ010J6INAJKEDWIJoV12/ewpWgv6akpfCN8lnPntqpBiMjRT30QNdiXIIrZUlRKuxbpjB1wHF/t3MMpx2YlOToRkcRTgqhBtN+hsKScz7fsJrtFU7pkN+eXl/VLcmQiIvUjoU1MZjbazJab2SozmxBnfmcze8fMFprZLDPLjZn3SzNbbGZLzexRM6vX8Stir1xatH4n2S3S63P3IiJJl7AEYWapwGPAeUBP4Eoz61ltsYnAs+7eF3gA+Hm47hnAUKAv0BsYDAxLVKzxFBTtSxCl5RGyWzStz92LiCRdImsQQ4BV7v6Zu+8FXgAuqrZMT2BGOD0zZr4DGUA60BRoAmxKYKz7KSgsJavpvha47CwlCBFpXBKZII4D1sa8XxeWxVoAjA2nLwGyzKydu39IkDA2hq833X1p9R2Y2Tgzyzez/IKCgjoNfktRKSe2b0FmeiqAahAi0ugk+zLX8cAwM5tH0IS0Hqgws5OAHkAuQVI528zOrL6yu09y9zx3z8vJyanTwAoKS2mf1ZTcNs0A1AchIo1OIhPEeuD4mPe5YVkld9/g7mPdfQBwV1i2g6A28ZG7F7l7EfAGcHoCY630t4Ub2FxYQkFhKdlZTcltE9wUl6MmJhFpZBKZIGYD3cysq5mlA1cAr8UuYGbZZhaN4U7gyXD6S4KaRZqZNSGoXezXxFTX9uyt4LY/zePXb69kW/Feclrsq0HkqIlJRBqZhCUIdy8HbgPeJDi5T3H3xWb2gJmNCRcbDiw3sxXAMcCDYflUYDXwKUE/xQJ3/2uiYo0qLCkD4PVPN+Ie1BpOzGlBWorRvmVGoncvItKgJPRGOXefBkyrVnZPzPRUgmRQfb0K4OZExhZPYWk5ADuKg0SR3aIpZ3XPYUjXtrRq1qS+wxERSapkd1I3KEUl5VXe52Q1pWlaKj06tExSRCIiyaMEEaOotGqCaK+OaRFpxJQgYhSGNYg+x7UCdO+DiDRuGqwvRrQGced53dmws4Rm4U1yIiKNkRJEjKLwKqbuHVpyxknZSY5GRCS51MQUI1qDaN5UNQcRESWIGIWl5aSnpdA0TQlCREQJIkZRSTktM9TqJiICShBVFJWW06KpEoSICChBVFFUUk4L1SBERAAliCoKVYMQEamkBBGjqKScFk015pKICChBVFFYWkaWmphERAAliCqCGoQShIgIKEFUcvfgKibVIEREACWISqXlEcoqXDUIEZGQEkQoOsyG+iBERAJKEKHow4JUgxARCShBhKI1CCUIEZFAQhOEmY02s+VmtsrMJsSZ39nM3jGzhWY2y8xyY+Z1MrPpZrbUzJaYWZdExhp9WJA6qUVEAglLEGaWCjwGnAf0BK40s57VFpsIPOvufYEHgJ/HzHsWeNjdewBDgM2JihVi+iB0o5yICJDYGsQQYJW7f+bue4EXgIuqLdMTmBFOz4zODxNJmru/BeDuRe5enMBYKSoNHhakGoSISCCRCeI4YG3M+3VhWawFwNhw+hIgy8zaAScDO8zsz2Y2z8weDmskCaNOahGRqpLdST0eGGZm84BhwHqgguBRqGeG8wcDJwDXV1/ZzMaZWb6Z5RcUFHytQAp1mauISBWJTBDrgeNj3ueGZZXcfYO7j3X3AcBdYdkOgtrG/LB5qhz4CzCw+g7cfZK757l7Xk5OztcKtqiknCapRtO0ZOdMEZGGIZFnw9lANzPrambpwBXAa7ELmFm2mUVjuBN4Mmbd1mYWPeufDSxJYKxsLy6jVbMmmFkidyMicsRIWIII//O/DXgTWApMcffFZvaAmY0JFxsOLDezFcAxwIPhuhUEzUvvmNmngAFPJCpWgILCEnKyMhK5CxGRI0pCG9zdfRowrVrZPTHTU4GpNaz7FtA3kfHFKigsJSeraX3tTkSkwVODe2hzYSk5LZQgRESilCCASMTZUlRK+5ZKECIiUUoQwM49ZZRVuGoQIiIxlCAImpcA1SBERGIoQRB0UAOqQYiIxFCCAAqKSgBo31KXuYqIRClBAJt3hTUIXeYqIlJJCYKgialZk1Sapyd0PEARkSOKEgRBJ3X7lk01zIaISAwlCMK7qNVBLSJShRIEUKCb5ERE9qMEAWzeVaIahIhINY0+QZSUVbCrpFxXMImIVNPoE0RhSTknZDcnt01mskMREWlQGv3zNXOymjJj/PBkhyEi0uA0+hqEiIjEd9AEYWa3m1mb+ghGREQajtrUII4BZpvZFDMbbbqbTESkUThognD3u4FuwB+A64GVZvZfZnZigmMTEZEkqlUfhLs78FX4KgfaAFPN7JcHWi+scSw3s1VmNiHO/M5m9o6ZLTSzWWaWW21+SzNbZ2b/W+tPJCIidaI2fRA/MLM5wC+BfwJ93P1WYBBw6QHWSwUeA84DegJXmlnPaotNBJ51977AA8DPq83/KfBuLT+LiIjUodrUINoCY919lLu/5O5lAO4eAS44wHpDgFXu/pm77wVeAC6qtkxPYEY4PTN2vpkNIuj/mF6rTyIiInWqNgniDWBb9E3Y7HMqgLsvPcB6xwFrY96vC8tiLQDGhtOXAFlm1s7MUoBfAeNrEZ+IiCRAbRLEb4GimPdFYVldGA8MM7N5wDBgPVABfB+Y5u7rDrSymY0zs3wzyy8oKKijkEREBGp3J7WFndRA0LRkZrVZbz1wfMz73LCskrtvIKxBmFkL4FJ332FmpwNnmtn3gRZAupkVufuEautPAiYB5OXlOSIiUmdqU4P4zMz+zcyahK8fAJ/VYr3ZQDcz62pm6cAVwGuxC5hZdticBHAn8CSAu1/t7p3cvQtBLePZ6slBREQSqzYJ4hbgDIL//tcBpwLjDraSu5cDtwFvAkuBKe6+2MweMLMx4WLDgeVmtoKgQ/rBQ/4EIiKSEBbTenREy8vL8/z8/GSHISJyRDGzOe6eF2/eQfsSzCwD+B7QC8iIlrv7v9RZhCIi0uDUpolpMnAsMAr4B0Fnc2EigxIRkeSrTYI4yd3/H7Db3Z8BvkXQDyEiIkex2iSIsvDnDjPrDbQC2icuJBERaQhqcz/DpPB5EHcTXKbaAvh/CY1KRESS7oAJIrxHYZe7bycYNO+EeolKRESS7oBNTOGAfP9ZT7GIiEgDUps+iLfNbLyZHW9mbaOvhEcmIiJJVZs+iO+EP/81psxRcxPs2QHNWtf9diMRKFgGkfL95zVpBu1OAjPYuhr27g7KU5tA9imQUqtnQB1ZirdBRitISQ2OeXoLSE2Dwq+gaPO+5bK7BcdH5EhRXgpbVsDXvWG5SSZkn1Q3McU4aIJw9651vtejwdzJ8LcfwjUvwwnD4y/jDl98AKWHcNtIWTF88ChsmFfzMieeDalNYcUbVcuPGwRn3A5p4UmyZUfo0BdKdsKXH4NHgvLMtpA7OEgyh8IdvvwQSnYF71NSofMZkN686nIbF8CujYe27fg7hCWvwYI/wTG9oWN/mP+nIEF2PgPm/bFqEm15HHzzDsjqUAf7Fkmw4i3wj1/Cji++/raOy4Ob3vn626nmoENtmNl18crd/dk6j+ZrqNehNkp2wqMDgy+4fU+4+b3gP1qAvcWw9LUgKXz6Eqz9+NC3n9UBvjkeWhy7/7ytq+C9R8Ar4Bs/hJweQXnhRnj3YSjaVHX5bqNg/Zwg1lgnnAU9LgBqmSQ8Ev/zZHWE024J/qsH+PwfsOTV2m2zNlLTof9VsOod2LUhmP7in7Dtcxj0XThpZLBc2Z4gsX61sO72LZJoOT2Cv+Po38/hatYaunzjsFY90FAbtUkQv4l5mwGMAOa6+2WHFU2C1EuC2L0FZv8+OOGufAvO/BG89yvo821o3Tk4aX86FXaGz0lqngNn3QUd+h3afnK6Q3pmzfNLiwCHpllVy/fuhoLl+96vnA7//HWw/2E/DpppIDjJz/p5kOgORWY2nH33vs9TvBVm/Aw2zt+3TFqz4LicdM6hbbsmLTtC1rFBVXzv7qD2U74X9hYF07EiFbBpcfymOZGGJiUV2vfa989lknytBBFnY62BF9x9dF0EV1cSliC2fR6c9M/8EUy/Gz56HCwVzrgNzrkfXroelv513/LH9oaRDwT/GTRrDWlN6z6mulBWcugJIt7ncYfdBfvaUJu22L/JSUQarK81WF8cu4HG0y/x6Usw88HgP/p5fwxqC5f+ft/8y59JXmxfR5OM4PV1mUEL3VgvcjSqzWiufyW4agmCy2J7AlMSGVSDEu1AevMnwc9Tb0leLCIi9ag2NYiJMdPlwBcHe1b0UWXHWmjePmhG6TgAcuPWxEREjjq1SRBfAhvdvQTAzJqZWRd3X5PQyJJp/vNBJ+7tc4MO5y7fgO7fguyTkx2ZiEi9qc1dVS8BkZj3FWHZ0WvzkqBpaesq2LkOWh8PfS4L7ikQEWkkapMg0tx9b/RNOJ2euJCSZPdW2BBerhm9se2zWVCxF1p3SlpYIiLJUpsEUWBmY6JvzOwiYMsBlj8yffi/8OxFwXQ0Qax8M/jZSglCRBqf2iSIW4CfmNmXZvYl8GPg5tps3MxGm9lyM1tlZhPizO9sZu+Y2UIzm2VmuWF5fzP70MwWh/O+s//W69jeIijZARVl+xLEmveDn62PT/juRUQamtqMxbQaOM3MWoTvi2qzYTNLBR4DRgLrgNlm9pq7L4lZbCLwrLs/Y2ZnAz8HrgWKgevcfaWZdQTmmNmb7r7jUD7cIYnefVtaGCQLCJqXAFopQYhI43PQGoSZ/ZeZtXb3IncvMrM2ZvazWmx7CLDK3T8L+y1eAC6qtkxPYEY4PTM6391XuPvKcHoDsBnIqd1HOkwV4ZNVS3ZC6a595c3aBncHi4g0MrVpYjov9j/38Oly59diveOAtTHv14VlsRYAY8PpS4AsM2sXu4CZDSHoFF9di30evkhF8LNkZ1CLiI6Iqg5qEWmkapMgUs2scgAeM2sG1NUAQ+OBYWY2DxgGrCe4jDa6rw7AZOCG8Ol2VZjZODPLN7P8goKCrxdJJKxBlO4KBsM7blDwXv0PItJI1eZGueeAd8zsKYKxoa8HajMA0Xog9uyaG5ZVCpuPxgKEfRyXRmsrZtYSeB24y90/ircDd58ETIJgsL5axFSzaB9Eya6gBtGxf/BMhnZ1/xAOEZEjQW06qR8yswXAOQRjMr0JdK7FtmcD3cysK0FiuAK4KnYBM8sGtoW1gzuBJ8PydOAVgg7sqbX/OF9DtA+ieAtUlAYjl970TjDctIhII1Tb51NuIkgO3wbOBpYebAV3LwduI0goS4Ep7r7YzB6Iua9iOLDczFYAxwAPhuWXA98Erjez+eGrfy1jPTzRPoidYSWnaUto32PfMxRERBqZGmsQZnYycGX42gK8SPD8iLNqu3F3nwZMq1Z2T8z0VGC/GoK7/xH4Y233UyeiTUy7ogkiq+ZlRUQagQM1MS0D3gMucPdVAGb27/USVTJEO6l3hgPVft1HAIqIHOEO1MQ0FtgIzDSzJ8xsBLV+gPERKNrEtGtD8FM1CBFp5GpMEO7+F3e/AuhOcBPbD4H2ZvZbMzu3vgKsN9FO6l0xfRAiIo3YQTup3X23u//J3S8kuFR1HsF4TEeXaB9EWXHwUzUIEWnkansVExDcRe3uk9x9RKICSppoH0SUhtcQkUbukBLEUS1SUfW9ahAi0sgpQURFm5gAMGjSPGmhiIg0BEoQURUxTUzpLSBFh0ZEGjedBaNiaxBqXhIRUYKopAQhIlKFEkRUpHzfMyCUIERElCAqVZRBZvisIl3iKiKiBFEpUgGZbYJp1SBERJQgKkXKgudPg4bZEBFBCWKfSHlME5NqECIiShBRkXLIDGsQGupbREQJAoBIBDwS1CC6DoNOpyc7IhGRpDvoM6kbheg9EKnp8N3XkhuLiEgDoRoE7BvJNUX5UkQkKqEJwsxGm9lyM1tlZhPizO9sZu+Y2UIzm2VmuTHzvmtmK8PXdxMZ574aRJOE7kZE5EiSsARhZqnAY8B5QE/gSjPrWW2xicCz7t4XeAD4ebhuW+Be4FRgCHCvmbVJVKxUhAlCNQgRkUqJrEEMAVa5+2fuvhd4Abio2jI9gRnh9MyY+aOAt9x9m7tvB94CRics0ogShIhIdYlMEMcBa2PerwvLYi0AxobTlwBZZtauluvWHfVBiIjsJ9md1OOBYWY2DxgGrAcqDrzKPmY2zszyzSy/oKDg8KNQDUJEZD+JTBDrgeNj3ueGZZXcfYO7j3X3AcBdYdmO2qwbLjvJ3fPcPS8nJ+fwI40+blSd1CIilRKZIGYD3cysq5mlA1cAVW4yMLNsM4vGcCfwZDj9JnCumbUJO6fPDcsSI/o0uZTUhO1CRORIk7AE4e7lwG0EJ/alwBR3X2xmD5jZmHCx4cByM1sBHAM8GK67DfgpQZKZDTwQliVGZROTahAiIlEJbXR392nAtGpl98RMTwWm1rDuk+yrUSSWOqlFRPaT7E7qhkF9ECIi+1GCAPVBiIjEoQQB6oMQEYlDCQLUByEiEocSBOzrg1CCEBGppAQBMaO5KkGIiEQpQUBMJ7UShIhIlBIEqJNaRCQOJQjQYH0iInEoQYD6IERE4lCCAPVBiIjEoQQB6oMQEYlDCQLUByEiEocSBMQkCI3FJCISpQQBMZ3UamISEYlSggB1UouIxKEEATFjMakGISISpQQB4WiuBik6HCIiUTojQtAHof4HEZEqlCAg6INQ/4OISBUJTRBmNtrMlpvZKjObEGd+JzObaWbzzGyhmZ0fljcxs2fM7FMzW2pmdyYyTiIV6n8QEakmYQnCzFKBx4DzgJ7AlWbWs9pidwNT3H0AcAXweFj+baCpu/cBBgE3m1mXRMVKpEz3QIiIVJPIdpUhwCp3/wzAzF4ALgKWxCzjQMtwuhWwIaa8uZmlAc2AvcCuhEUaKVcTkzRaZWVlrFu3jpKSkmSHIgmUkZFBbm4uTZrUvrUkkWfF44C1Me/XAadWW+Y+YLqZ3Q40B84Jy6cSJJONQCbw7+6+rfoOzGwcMA6gU6dOhx+pOqmlEVu3bh1ZWVl06dIFM0t2OJIA7s7WrVtZt24dXbt2rfV6ye6kvhJ42t1zgfOByWaWQlD7qAA6Al2B/zCzE6qv7O6T3D3P3fNycnIOP4qKcjUxSaNVUlJCu3btlByOYmZGu3btDrmWmMgEsR44PuZ9blgW63vAFAB3/xDIALKBq4C/u3uZu28G/gnkJSzSSLk6qaVRU3I4+h3Od5zIBDEb6GZmXc0snaAT+rVqy3wJjAAwsx4ECaIgLD87LG8OnAYsS1ikEV3mKiJSXcIShLuXA7cBbwJLCa5WWmxmD5jZmHCx/wBuMrMFwPPA9e7uBFc/tTCzxQSJ5il3X5ioWIlUqA9CJEl27NjB448/fvAF4zj//PPZsWPHAZe55557ePvttw9r+42dBefjI19eXp7n5+cf3srPXQ5FX8HN79ZtUCJHgKVLl9KjR4+k7X/NmjVccMEFLFq0aL955eXlpKU1vtp9oj53vO/azOa4e9wm/GR3UjcM6oMQSZoJEyawevVq+vfvzx133MGsWbM488wzGTNmDD17BrdOXXzxxQwaNIhevXoxadKkynW7dOnCli1bWLNmDT169OCmm26iV69enHvuuezZsweA66+/nqlTp1Yuf++99zJw4ED69OnDsmVBy3VBQQEjR46kV69e3HjjjXTu3JktW7bsF+utt95KXl4evXr14t57760snz17NmeccQb9+vVjyJAhFBYWUlFRwfjx4+nduzd9+/blN7/5TZWYAfLz8xk+fDgA9913H9deey1Dhw7l2muvZc2aNZx55pkMHDiQgQMH8sEHH1Tu76GHHqJPnz7069ev8vgNHDiwcv7KlSurvD9cjS81x6M+CBEA7v/rYpZsqNtbjnp2bMm9F/aqcf4vfvELFi1axPz58wGYNWsWc+fOZdGiRZWXZD755JO0bduWPXv2MHjwYC699FLatWtXZTsrV67k+eef54knnuDyyy/n5Zdf5pprrtlvf9nZ2cydO5fHH3+ciRMn8vvf/57777+fs88+mzvvvJO///3v/OEPf4gb64MPPkjbtm2pqKhgxIgRLFy4kO7du/Od73yHF198kcGDB7Nr1y6aNWvGpEmTWLNmDfPnzyctLY1t2/a7Un8/S5Ys4f3336dZs2YUFxfz1ltvkZGRwcqVK7nyyivJz8/njTfe4NVXX+Xjjz8mMzOTbdu20bZtW1q1asX8+fPp378/Tz31FDfccMNB93cwOitCONSGDoVIQzFkyJAq1+s/+uijvPLKKwCsXbuWlStX7pcgunbtSv/+/QEYNGgQa9asibvtsWPHVi7z5z//GYD333+/cvujR4+mTZs2cdedMmUKkyZNory8nI0bN7JkyRLMjA4dOjB48GAAWrYM7v19++23ueWWWyqbitq2bXvQzz1mzBiaNWsGBDcw3nbbbcyfP5/U1FRWrFhRud0bbriBzMzMKtu98cYbeeqpp3jkkUd48cUX+eSTTw66v4PRWRGCJqYmzZIdhUjSHeg//frUvHnzyulZs2bx9ttv8+GHH5KZmcnw4cPjXs/ftGnTyunU1NTKJqaalktNTaW8vLzWMX3++Ui8IAcAAA7RSURBVOdMnDiR2bNn06ZNG66//vrDuvs8LS2NSCQCsN/6sZ/7v//7vznmmGNYsGABkUiEjIyMA2730ksvrawJDRo0aL8EejjUBwEazVUkibKysigsLKxx/s6dO2nTpg2ZmZksW7aMjz76qM5jGDp0KFOmTAFg+vTpbN++fb9ldu3aRfPmzWnVqhWbNm3ijTfeAOCUU05h48aNzJ49G4DCwkLKy8sZOXIk//d//1eZhKJNTF26dGHOnDkAvPzyyzXGtHPnTjp06EBKSgqTJ0+moiJ4sNnIkSN56qmnKC4urrLdjIwMRo0axa233lonzUugBBFQJ7VI0rRr146hQ4fSu3dv7rjjjv3mjx49mvLycnr06MGECRM47bTT6jyGe++9l+nTp9O7d29eeukljj32WLKysqos069fPwYMGED37t256qqrGDp0KADp6em8+OKL3H777fTr14+RI0dSUlLCjTfeSKdOnejbty/9+vXjT3/6U+W+fvCDH5CXl0dqas0jOHz/+9/nmWeeoV+/fixbtqyydjF69GjGjBlDXl4e/fv3Z+LEiZXrXH311aSkpHDuuefWyXHRZa4Aj58ObU+AK56r26BEjgDJvsy1ISgtLSU1NZW0tDQ+/PBDbr311spO8yPJxIkT2blzJz/96U/jzj/Uy1zVrgIarE+kkfvyyy+5/PLLiUQipKen88QTTyQ7pEN2ySWXsHr1ambMmFFn21SCAPVBiDRy3bp1Y968eckO42uJXoVVl9QHAXqinIhIHEoQoCfKiYjEoQQBeqKciEgcShCgTmoRkTiUICB8opxqECLJ8HWG+wb4n//5n8qbxqRuKUGAmphEkuhoSBCHMmTHkUQJAjSaq0gSVR/uG+Dhhx9m8ODB9O3bt3JY7d27d/Otb32Lfv360bt3b1588UUeffRRNmzYwFlnncVZZ52137YfeOABBg8eTO/evRk3bhzRG4NXrVrFOeecQ79+/Rg4cCCrV68G9h9GG2D48OFEb8LdsmULXbp0AeDpp59mzJgxnH322YwYMYKioiJGjBhROZT4q6++WhnHs88+W3lH9bXXXkthYSFdu3alrKwMCIbxiH3fUOis6K4+CJGoNybAV5/W7TaP7QPn/aLG2dWH+54+fTorV67kk08+wd0ZM2YM7777LgUFBXTs2JHXX38dCMYqatWqFY888ggzZ84kOzt7v23fdttt3HPPPQBce+21/O1vf+PCCy/k6quvZsKECVxyySWUlJQQiUTiDqN9MHPnzmXhwoW0bduW8vJyXnnlFVq2bMmWLVs47bTTGDNmDEuWLOFnP/sZH3zwAdnZ2Wzbto2srCyGDx/O66+/zsUXX8wLL7zA2LFjadKkYZ2HVIOIBANgqQYh0jBMnz6d6dOnM2DAAAYOHMiyZctYuXIlffr04a233uLHP/4x7733Hq1atTrotmbOnMmpp55Knz59mDFjBosXL6awsJD169dzySWXAMEgd5mZmTUOo30gI0eOrFzO3fnJT35C3759Oeecc1i/fj2bNm1ixowZfPvb365MYNWH5wbq7PkNdU1nxUjYdqgEIXLA//Tri7tz5513cvPNN+83b+7cuUybNo27776bESNGVNYO4ikpKeH73/8++fn5HH/88dx3330JHZ77ueeeo6CggDlz5tCkSRO6dOlywP0NHTqUNWvWMGvWLCoqKujdu/chx5ZoCa1BmNloM1tuZqvMbEKc+Z3MbKaZzTOzhWZ2fsy8vmb2oZktNrNPzezAg6EfrkjY5qcEIZIU1Yf7HjVqFE8++SRFRUUArF+/ns2bN7NhwwYyMzO55ppruOOOO5g7d27c9aOiJ+fs7GyKiooqHzualZVFbm4uf/nLX4BgoL7i4uIah9GOHZ47uo14du7cSfv27WnSpAkzZ87kiy++AODss8/mpZdeYuvWrVW2C3Dddddx1VVXNcjaAyQwQZhZKvAYcB7QE7jSzHpWW+xuYIq7DwCuAB4P100D/gjc4u69gOFAYnpvVIMQSarqw32fe+65XHXVVZx++un06dOHyy67jMLCQj799FOGDBlC//79uf/++7n77rsBGDduHKNHj96vk7p169bcdNNN9O7dm1GjRlU+8Q1g8uTJPProo/Tt25czzjiDr776qsZhtMePH89vf/tbBgwYEPc51VFXX301+fn59OnTh2effZbu3bsD0KtXL+666y6GDRtGv379+NGPflRlne3bt3PllVfW2fGsSwkb7tvMTgfuc/dR4fs7Adz95zHL/B/wmbs/FC7/K3c/I6xJXOXu+z9QtgaHPdz37i3w8Ilw/kQYctOhry9yhNNw38kzdepUXn31VSZPnlwv+2tIw30fB6yNeb8OOLXaMvcB083sdqA5cE5YfjLgZvYmkAO84O6/TEiUTVvCda9BuxMTsnkRkXhuv/123njjDaZNm5bsUGqU7HaVK4Gn3f1XYQ1ispn1DuP6BjAYKAbeCbPcO7Erm9k4YBxAp06dDi+CtHQ4YdjhfwIRkcPwm9/8JtkhHFQiO6nXA8fHvM8Ny2J9D5gC4O4fAhlANkFt41133+LuxcA0YGD1Hbj7JHfPc/e8nJycBHwEkcbhaHmypNTscL7jRCaI2UA3M+tqZukEndCvVVvmS2AEgJn1IEgQBcCbQB8zyww7rIcBSxIYq0ijlZGRwdatW5UkjmLuztatW8nIOLSLQRPWxOTu5WZ2G8HJPhV40t0Xm9kDQL67vwb8B/CEmf074MD1HvyWbjezRwiSjAPT3P31RMUq0pjl5uaybt06CgoKkh2KJFBGRga5ubmHtE7CrmKqb4d9FZOISCN2oKuYNNSGiIjEpQQhIiJxKUGIiEhcR00fhJkVAF8cxqrZQM33zydPQ40LGm5siuvQNNS4oOHGdjTG1dnd494ncNQkiMNlZvk1ddAkU0ONCxpubIrr0DTUuKDhxtbY4lITk4iIxKUEISIicSlBwKRkB1CDhhoXNNzYFNehaahxQcONrVHF1ej7IEREJD7VIEREJC4lCBERiatRJ4iDPTO7HuM4Pnw295LwGdw/CMvvM7P1ZjY/fJ1/sG0lILY14TPB55tZfljW1szeMrOV4c829RzTKTHHZL6Z7TKzHybreJnZk2a22cwWxZTFPUYWeDT8nVtoZvsNY5/guB42s2Xhvl8xs9ZheRcz2xNz7H5Xz3HV+N2Z2Z3h8VpuZqPqOa4XY2JaY2bzw/L6PF41nR8S/zvm7o3yRTDC7GrgBCAdWAD0TFIsHYCB4XQWsILgOd73AeOTfJzWANnVyn4JTAinJwAPJfl7/AronKzjBXyT4Hkliw52jIDzgTcAA04DPq7nuM4F0sLph2Li6hK7XBKOV9zvLvw7WAA0BbqGf7Op9RVXtfm/Au5JwvGq6fyQ8N+xxlyDGAKscvfP3H0v8AJwUTICcfeN7j43nC4ElhI8srWhugh4Jpx+Brg4ibGMAFa7++HcRV8n3P1dYFu14pqO0UXAsx74CGhtZh3qKy53n+7u5eHbjwge5FWvajheNbmI4JHDpe7+ObCK4G+3XuMyMwMuB55PxL4P5ADnh4T/jjXmBBHvmdlJPymbWRdgAPBxWHRbWE18sr6bckJO8NzwORY84hXgGHffGE5/BRyThLiirqDqH22yj1dUTceoIf3e/QvBf5pRXc1snpn9w8zOTEI88b67hnK8zgQ2ufvKmLJ6P17Vzg8J/x1rzAmiwTGzFsDLwA/dfRfwW+BEoD+wkaCKW9++4e4DgfOAfzWzb8bO9KBOm5RrpS14UuEY4KWwqCEcr/0k8xjVxMzuAsqB58KijUAndx8A/Aj4k5m1rMeQGuR3F+NKqv4jUu/HK875oVKifscac4KozTOz642ZNSH48p9z9z8DuPsmd69w9wjwBAmqWh+Iu68Pf24GXglj2BStsoY/N9d3XKHzgLnuvimMMenHK0ZNxyjpv3dmdj1wAXB1eGIhbMLZGk7PIWjrP7m+YjrAd9cQjlcaMBZ4MVpW38cr3vmBevgda8wJojbPzK4XYfvmH4Cl7v5ITHlsu+ElwKLq6yY4ruZmlhWdJujgXERwnL4bLvZd4NX6jCtGlf/qkn28qqnpGL0GXBdeaXIasDOmmSDhzGw08J/AGHcvjinPMbPUcPoEoBvwWT3GVdN39xpwhZk1NbOuYVyf1FdcoXOAZe6+LlpQn8erpvMD9fE7Vh+98A31RdDbv4Ig+9+VxDi+QVA9XAjMD1/nA5OBT8Py14AO9RzXCQRXkCwAFkePEdAOeAdYCbwNtE3CMWsObAVaxZQl5XgRJKmNQBlBe+/3ajpGBFeWPBb+zn0K5NVzXKsI2qejv2e/C5e9NPyO5wNzgQvrOa4avzvgrvB4LQfOq8+4wvKngVuqLVufx6um80PCf8c01IaIiMTVmJuYRETkAJQgREQkLiUIERGJSwlCRETiUoIQqSNmdr2ZdUx2HCJ1RQlCpO5cD8RNENFr5kWOJEoQIgcQDuu81MyeCIdanm5mzeIsdxmQBzwXDv/cLBwe+iEzmwt828xONLO/h+NavWdm3cN1c8zsZTObHb6GhuXDYoaTnhe9aVGkvihBiBxcN+Axd+8F7CC4SaoKd58K5BMMX9Hf3feEs7a6+0B3f4HgucG3u/sgYDzweLjMr4H/dvfB4bZ/H5aPB/7V3fsTDBYX3aZIvUhLdgAiR4DP3X1+OD2H4FkAtfUiVA60dgbwUjByAhA84wCCoRx6xpS3DJf/J/CImT0H/NljhnoQqQ9KECIHVxozXQHs18R0ALvDnynAjrA2UF0KcJq7l1Qr/4WZvU4wrMI/zWyUuy87hH2LfC1qYhKpO4UET/zajwfDM39uZt+GysdC9gtnTwdujy5rZv3Dnye6+6fu/hDB4JLdExm8SHVKECJ152ngd9FO6jjzrwa+Z2bRwQ+jTzD8NyAvfFjOEuCWsPyHZrbIzBYSDCD3xn5bFEkgDdYnIiJxqQYhIiJxqZNa5BCZ2WPA0GrFv3b3p5IRj0iiqIlJRETiUhOTiIjEpQQhIiJxKUGIiEhcShAiIhKXEoSIiMSlBCEiInH9f9idY/+PncGKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_accuracy = [] \n",
    "test_accuracy = []\n",
    "settings = range(1, 201)\n",
    "for f in settings:\n",
    "    clf = RandomForestClassifier(n_estimators=f, n_jobs=-1, random_state=0) \n",
    "    clf.fit(data_train, target_train)\n",
    "    training_accuracy.append(clf.score(data_train, target_train))\n",
    "    test_accuracy.append(clf.score(data_test, target_test))\n",
    "plt.plot(settings, training_accuracy, label=\"training accuracy\") \n",
    "plt.plot(settings, test_accuracy, label=\"test accuracy\") \n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_trees\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like in this case the more trees we build the more accurate our model gets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*max_depth* represents the depth of each tree in the forest. The deeper the tree, the more splits it has and it captures more information about the data. We fit each decision tree with depths ranging from 1 to 32 and plot the training and test errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "   rf = RandomForestClassifier(max_depth=max_depth, n_jobs=-1)\n",
    "   rf.fit(data_train, target_train)\n",
    "   train_pred = rf.predict(data_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(target_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = rf.predict(data_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(target_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our model overfits for large depth values. The trees perfectly predicts all of the train data, however, it fails to generalize the findings for new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum number of samples (split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*min_samples_split* represents the minimum number of samples required to split an internal node. This can vary between considering at least one sample at each node to considering all of the samples at each node. When we increase this parameter, each tree in the forest becomes more constrained as it has to consider more samples at each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split set to 2\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.930\n",
      "min_samples_split set to 3\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.928\n",
      "min_samples_split set to 4\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.929\n",
      "min_samples_split set to 5\n",
      "Accuracy on training set: 0.998\n",
      "Accuracy on test set: 0.929\n",
      "min_samples_split set to 6\n",
      "Accuracy on training set: 0.997\n",
      "Accuracy on test set: 0.930\n",
      "min_samples_split set to 7\n",
      "Accuracy on training set: 0.993\n",
      "Accuracy on test set: 0.930\n",
      "min_samples_split set to 8\n",
      "Accuracy on training set: 0.989\n",
      "Accuracy on test set: 0.929\n",
      "min_samples_split set to 9\n",
      "Accuracy on training set: 0.982\n",
      "Accuracy on test set: 0.929\n",
      "min_samples_split set to 10\n",
      "Accuracy on training set: 0.978\n",
      "Accuracy on test set: 0.930\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,11):\n",
    "    print(\"min_samples_split set to %s\" % i)\n",
    "    tree = RandomForestClassifier(min_samples_split=i) \n",
    "    tree.fit(data_train, target_train)\n",
    "    print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "    print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in this case improving the minimum value doesn't necessarily improve the accuracy, so we can keep the default value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum number of samples (leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*min_samples_leaf* is the minimum number of samples required to be at a leaf node. This parameter is similar to min_samples_splits, however, this describe the minimum number of samples at the leafs, the base of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split set to 1\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.929\n",
      "min_samples_split set to 2\n",
      "Accuracy on training set: 0.995\n",
      "Accuracy on test set: 0.930\n",
      "min_samples_split set to 3\n",
      "Accuracy on training set: 0.967\n",
      "Accuracy on test set: 0.930\n",
      "min_samples_split set to 4\n",
      "Accuracy on training set: 0.943\n",
      "Accuracy on test set: 0.930\n",
      "min_samples_split set to 5\n",
      "Accuracy on training set: 0.932\n",
      "Accuracy on test set: 0.929\n",
      "min_samples_split set to 6\n",
      "Accuracy on training set: 0.927\n",
      "Accuracy on test set: 0.929\n",
      "min_samples_split set to 7\n",
      "Accuracy on training set: 0.926\n",
      "Accuracy on test set: 0.929\n",
      "min_samples_split set to 8\n",
      "Accuracy on training set: 0.924\n",
      "Accuracy on test set: 0.929\n",
      "min_samples_split set to 9\n",
      "Accuracy on training set: 0.924\n",
      "Accuracy on test set: 0.929\n",
      "min_samples_split set to 10\n",
      "Accuracy on training set: 0.924\n",
      "Accuracy on test set: 0.928\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    print(\"min_samples_split set to %s\" % i)\n",
    "    tree = RandomForestClassifier(min_samples_leaf=i) \n",
    "    tree.fit(data_train, target_train)\n",
    "    print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "    print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same conclusion as the last experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*max_features* represents the number of features to consider when looking for the best split. Since we're working with 119 different features, let's try all the values and see how relevant they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-51eb7210c785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtraining_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_accuracy = [] \n",
    "test_accuracy = []\n",
    "settings = range(1, 120)\n",
    "for f in settings:\n",
    "    clf = RandomForestClassifier(max_features=f, n_jobs=-1)\n",
    "    clf.fit(data_train, target_train)\n",
    "    training_accuracy.append(clf.score(data_train, target_train))\n",
    "    test_accuracy.append(clf.score(data_test, target_test))\n",
    "plt.plot(settings, training_accuracy, label=\"training accuracy\") \n",
    "plt.plot(settings, test_accuracy, label=\"test accuracy\") \n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_features\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosted regression trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principle : In contrast to the random forest approach, gradient boosting works by building trees in a serial man ner, where each tree tries to correct the mistakes of the previous one. By default, there is no randomization in gradient boosted regression trees; instead, strong pre-pruning is used. Gradient boosted trees often use very shallow trees, of depth one to five, which makes the model smaller in terms of memory and makes predictions faster. Each tree can only provide good predictions on part of the data, and so more and more trees are added to iteratively improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.981\n",
      "Accuracy on test set: 0.819\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../dumps/2020.01.13-14.25.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = 0.20, random_state = 0)\n",
    "\n",
    "tree = GradientBoostingClassifier(random_state=0)\n",
    "tree.fit(data_train, target_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the training set accuracy is quite close to 100% and the test set accuracy is pretty low, we are likely to be overfitting. To reduce this overfitting, we mght try to apply pre-pruning by limiting the maximum depth or lower the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now carry on with a bigger dataset and try with different values of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_csv('../dumps/2020.02.10-12.14.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4ea04b7f0905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmax_depths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0mfalse_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m   1536\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1592\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1245\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "   rf = GradientBoostingClassifier(max_depth=max_depth, random_state=0)\n",
    "   rf.fit(data_train, target_train)\n",
    "   train_pred = rf.predict(data_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(target_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = rf.predict(data_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(target_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*learning_rate* shrinks the contribution of each tree by learning_rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
    "train_results = []\n",
    "test_results = []\n",
    "for eta in learning_rates:\n",
    "   model = GradientBoostingClassifier(learning_rate=eta)\n",
    "   model.fit(data_train, target_train)\n",
    "   train_pred = model.predict(data_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(target_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = model.predict(data_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(target_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(learning_rates, train_results, 'b', label=\"Train AUC\")\n",
    "line2, = plt.plot(learning_rates, test_results, 'r', label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('learning rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = [] \n",
    "test_accuracy = []\n",
    "settings = range(1, 201)\n",
    "for f in settings:\n",
    "    clf = GradientBoostingClassifier(n_estimators=f, n_jobs=-1, random_state=0) \n",
    "    clf.fit(data_train, target_train)\n",
    "    training_accuracy.append(clf.score(data_train, target_train))\n",
    "    test_accuracy.append(clf.score(data_test, target_test))\n",
    "plt.plot(settings, training_accuracy, label=\"training accuracy\") \n",
    "plt.plot(settings, test_accuracy, label=\"test accuracy\") \n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_trees\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum number of samples (split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,11):\n",
    "    print(\"min_samples_split set to %s\" % i)\n",
    "    tree = GradientBoostingClassifier(min_samples_split=i) \n",
    "    tree.fit(data_train, target_train)\n",
    "    print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "    print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum number of samples (leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    print(\"min_samples_split set to %s\" % i)\n",
    "    tree = GradientBoostingClassifier(min_samples_leaf=i) \n",
    "    tree.fit(data_train, target_train)\n",
    "    print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "    print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = [] \n",
    "test_accuracy = []\n",
    "settings = range(1, 120)\n",
    "for f in settings:\n",
    "    clf = RandomForestClassifier(max_features=f, n_jobs=-1)\n",
    "    clf.fit(data_train, target_train)\n",
    "    training_accuracy.append(clf.score(data_train, target_train))\n",
    "    test_accuracy.append(clf.score(data_test, target_test))\n",
    "plt.plot(settings, training_accuracy, label=\"training accuracy\") \n",
    "plt.plot(settings, test_accuracy, label=\"test accuracy\") \n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_features\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
